{"cells":[{"cell_type":"code","source":["# here we are mounting our S3 bucket with a specific MOUNT_NAME\ntry:\n  import urllib\n  ACCESS_KEY =\"XX\"\n  SECRET_KEY =\"XX\"\n  ENCODED_SECRET_KEY = urllib.parse.quote(SECRET_KEY,\"\")\n  AWS_BUCKET_NAME = \"sree-databricks-test1\"\n  MOUNT_NAME = \"s3datav3\"\n  #dbutils.fs.unmount(\"/mnt/MOUNT_NAME\")\n  dbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n  display(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))\nexcept Exception as e:\n  print(\"S3 already mounted\") \n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">S3 already mounted\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["MOUNT_NAME = \"s3datav3\"\n#display(dbutils.fs.ls(\"/mnt/%s/alphav/\" % MOUNT_NAME))\ndisplay(dbutils.fs.ls(\"dbfs:/mnt/%s/results/\" % MOUNT_NAME))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/s3datav3/results/r2results.csv</td><td>r2results.csv</td><td>2335</td></tr><tr><td>dbfs:/mnt/s3datav3/results/r2results_withfeatures.csv</td><td>r2results_withfeatures.csv</td><td>2317</td></tr><tr><td>dbfs:/mnt/s3datav3/results/test/</td><td>test/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["#\"MMM\", \"AXP\", \"AAPL\", \"BA\", \"CAT\", \"CVX\", \"CSC\", \"KO\", \"DIS\", \"DOW\", \"XOM\", \"GS\", \"HD\", \"IBM\", \"INT\", \"JNJ\", \"JPM\", \"MCD\", \"MRK\", \"MSF\", \"NKE\", \"PFE\", \"PG\", \"TRV\", \"UTX\", \"UNH\", \"VZ\", \"V\", \"WMT\", \"WBA\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["from datetime import datetime"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# We moved this part to the ETL part. this code needs to be removed \ndef clean_dataframe(df_data1):\n  df_data1 = df_data1.drop('_c0')\n  df_data1 = df_data1.drop('1. open')\n  df_data1 = df_data1.drop('2. high')\n  df_data1 = df_data1.drop('3. low')\n  df_data1 = df_data1.drop('5. volume')\n  df_data1 = df_data1.drop('VWAP')\n  df_data1 = df_data1.withColumnRenamed(\"4. close\",\"close\")\n  df_data1.dropna()\n  return df_data1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# HERE we are diving the data into train and test\nfrom pyspark.sql.functions import unix_timestamp, lit\ndef get_train_testdata(df_data1):\n  train_data = df_data1.filter(df_data1[\"DailyDate\"] < unix_timestamp(lit('2016-06-01 00:00:00')).cast('timestamp'))\n  test_data  = df_data1.filter(df_data1[\"DailyDate\"] > unix_timestamp(lit('2016-06-01 00:00:00')).cast('timestamp'))\n  print(\"Number of training records: \" + str(train_data.count()))\n  print(\"Number of testing records : \" + str(test_data.count()))\n  return train_data, test_data"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler,RFormula\nfrom pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression, DecisionTreeRegressor\nfrom pyspark.ml.regression import LinearRegressionModel\nfrom pyspark.ml import Pipeline, Model,PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator \nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder \nimport sklearn.metrics\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.sql.functions import monotonically_increasing_id, lag\nfrom pyspark.sql.window import Window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["\n# this is a dataframe which holds the r2 value for each ticker and model associated with it\n# in this, initialising\nresult_summary = spark.range(0).drop(\"id\")\nr2_columns = ['ticker', 'LR_R2', 'LR_RMSE','XG_R2','XG_RMSE']\nresult_summary = spark.createDataFrame([('Test',4.0,5.0,7.0,8.0)], r2_columns)\nfirstrow = spark.createDataFrame([('Test',4.0,5.0,7.0,8.0)], r2_columns)\nresult_summary = result_summary.union(firstrow )\nresult_summary.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-----+-------+-----+-------+\nticker|LR_R2|LR_RMSE|XG_R2|XG_RMSE|\n+------+-----+-------+-----+-------+\n  Test|  4.0|    5.0|  7.0|    8.0|\n  Test|  4.0|    5.0|  7.0|    8.0|\n+------+-----+-------+-----+-------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# We are removing the columns that causes a dataleakage \ndef removecolumns(train_data):\n  columns = train_data.columns\n  columns.remove('close_lag7D')\n  columns.remove('DailyDate')\n  columns.remove('close_lag14D')\n  columns.remove('close_lag28D')\n  columns.remove('close_lag50D')\n  columns.remove('close_lag200D')\n  return columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# HERE we are running the model for all the Dow 30 tickers. \n\n#stockList = [\"MMM\", \"AAPL\"] #[\"MMM\", \"AXP\", \"AAPL\", \"BA\", \"CAT\"] \n             \nstockList = [\"MMM\", \"AXP\", \"AAPL\", \"BA\", \"CAT\", \"CVX\", \"KO\", \"DIS\", \"XOM\", \"GS\", \"HD\", \"IBM\", \"INT\", \"JNJ\", \"JPM\", \"MCD\", \"MRK\", \"MSF\", \"NKE\", \"PFE\", \"PG\", \"TRV\", \"UTX\", \"UNH\", \"VZ\", \"V\", \"WMT\", \"WBA\"]\n\nMOUNT_NAME = \"s3datav3\"\n\nfor stock in stockList:\n  #stockList = [\"MMM\", \"AAPL\"] #[\"MMM\", \"AXP\", \"AAPL\", \"BA\", \"CAT\"] \n  df_data1 = spark.read\\\n      .format(\"csv\")\\\n      .option('header', 'true')\\\n      .option('inferSchema', 'true')\\\n      .load(\"/mnt/\"+MOUNT_NAME +\"/alphaandfeatures/\" + stock+ \".csv\" )\n  #df_data1.head(5)\n  df_data2 = df_data1.drop('_c0').dropna()\n\n  train_data, test_data = get_train_testdata(df_data2)\n  columns = removecolumns(train_data)\n  \n \n  #Formula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n  \n  formula = \"{} ~ {}\".format(\"close_lag7D\", \" + \".join(columns))\n  print(\"Formula : {}\".format(formula))\n  rformula = RFormula(formula = formula)\n  lr = LinearRegression()\n  pipeline = Pipeline(stages=[rformula, lr])\n  # Parameter grid\n  paramGrid = ParamGridBuilder()\\\n           .addGrid(lr.regParam,[0.01, .04])\\\n            .build()\n  cv = CrossValidator()\\\n        .setEstimator(pipeline)\\\n        .setEvaluator(RegressionEvaluator()\\\n                         .setMetricName(\"r2\"))\\\n        .setEstimatorParamMaps(paramGrid)\\\n        .setNumFolds(3)\n\n  cvModel = cv.fit(train_data)\n  cvModel.avgMetrics\n  predictions = cvModel.transform(test_data)\n  evaluator = RegressionEvaluator(labelCol=\"label\",\n                                    predictionCol=\"prediction\",\n                                    metricName=\"rmse\")\n\n  y_true = predictions.select('label').toPandas()\n  y_pred  = predictions.select('prediction').toPandas()\n\n  r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n  print('r2_score: {0}'.format(r2_score))\n\n  rmse = evaluator.evaluate(predictions)\n  print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n\n  print(cvModel.explainParams())\n  firstrow = spark.createDataFrame([(stock,format(r2_score),format(rmse),format(r2_score),format(rmse))], r2_columns)\n  result_summary = result_summary.union(firstrow )\n\n#df_data.show(5)\n#df2 = df_data1.toPandas()\n#df2.isnull().sum()\n#df2 = df_data1.toPandas()\n#df2.size\n#df2.dtypes\n#df2.count()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.778889708870703\nRoot Mean Squared Error (RMSE) on test data = 3.21909\nestimator: estimator to be cross-validated (current: Pipeline_3b7239a3fbb8)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_d7fa2b319ea3&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_d7fa2b319ea3&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_24e8cab2ef22)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.8961289527014993\nRoot Mean Squared Error (RMSE) on test data = 2.18302\nestimator: estimator to be cross-validated (current: Pipeline_417d10aaf13b)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_a96b5eb7b5ea&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_a96b5eb7b5ea&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_b462878939c2)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: -0.77004963948451\nRoot Mean Squared Error (RMSE) on test data = 19.0569\nestimator: estimator to be cross-validated (current: Pipeline_55bbc69b3f8f)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_f9ee8232bfd7&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_f9ee8232bfd7&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_9913b2a5994c)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.960221141052438\nRoot Mean Squared Error (RMSE) on test data = 3.6545\nestimator: estimator to be cross-validated (current: Pipeline_0aeb8fc35ccf)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_9103f3608368&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_9103f3608368&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_bb122872bde1)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Hist + MACD + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.7068957559801414\nRoot Mean Squared Error (RMSE) on test data = 3.80786\nestimator: estimator to be cross-validated (current: Pipeline_ab3bfa76ca22)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_ad4e775a1028&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_ad4e775a1028&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_90229a539cee)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.7993927475496361\nRoot Mean Squared Error (RMSE) on test data = 2.59339\nestimator: estimator to be cross-validated (current: Pipeline_464081c75ffd)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_490eddff1ada&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_490eddff1ada&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_f0155cd991fc)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.5133430170554745\nRoot Mean Squared Error (RMSE) on test data = 0.951428\nestimator: estimator to be cross-validated (current: Pipeline_f9874aa34046)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_0ef456c404d0&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_0ef456c404d0&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_2aa988634d13)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Signal + MACD_Hist + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.9047289043085577\nRoot Mean Squared Error (RMSE) on test data = 2.26868\nestimator: estimator to be cross-validated (current: Pipeline_a77b120bb7ad)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_93b03ece2a65&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_93b03ece2a65&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_5b9750aff3b0)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.6597778420287399\nRoot Mean Squared Error (RMSE) on test data = 2.12476\nestimator: estimator to be cross-validated (current: Pipeline_5562382739f1)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_abbbe1f39bf3&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_abbbe1f39bf3&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_e2c58e0a21a1)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.9329992837687289\nRoot Mean Squared Error (RMSE) on test data = 9.7431\nestimator: estimator to be cross-validated (current: Pipeline_91d7cbdd68c2)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_d9655405a137&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_d9655405a137&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_c75c4d2d4c2b)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Hist + MACD + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.8183854676783929\nRoot Mean Squared Error (RMSE) on test data = 3.17546\nestimator: estimator to be cross-validated (current: Pipeline_dbfe633d070e)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_2b57c5b9056a&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_2b57c5b9056a&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_c4ee7265d9d3)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.4441028304022917\nRoot Mean Squared Error (RMSE) on test data = 6.94138\nestimator: estimator to be cross-validated (current: Pipeline_3b31d017da3b)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_e800aafc55db&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_e800aafc55db&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_3ca0ced1d10d)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.6359993290565151\nRoot Mean Squared Error (RMSE) on test data = 2.33931\nestimator: estimator to be cross-validated (current: Pipeline_f996360c0497)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_7d47363e2f05&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_7d47363e2f05&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_97c9fbd6ac30)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.6018796087264624\nRoot Mean Squared Error (RMSE) on test data = 2.78219\nestimator: estimator to be cross-validated (current: Pipeline_8529c7ce4f15)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_dad010fc853c&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_dad010fc853c&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_5fd4337ab172)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Hist + MACD + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.9376712622080364\nRoot Mean Squared Error (RMSE) on test data = 2.69347\nestimator: estimator to be cross-validated (current: Pipeline_5323fd1bc7b8)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_3a41c240113b&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_3a41c240113b&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_c9dd22c05d65)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.7349223888299787\nRoot Mean Squared Error (RMSE) on test data = 2.76177\nestimator: estimator to be cross-validated (current: Pipeline_5f7d6d3b1855)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_e9c11e2d4dbe&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_e9c11e2d4dbe&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_1703920a83cd)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.4749928875102779\nRoot Mean Squared Error (RMSE) on test data = 1.78031\nestimator: estimator to be cross-validated (current: Pipeline_54385c696cbd)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_e1f9184e4dab&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_e1f9184e4dab&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_7d1a8d46ce20)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA_x + EMA_y + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.6684602426174241\nRoot Mean Squared Error (RMSE) on test data = 0.335184\nestimator: estimator to be cross-validated (current: Pipeline_bc6db4983e9b)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_b46eb99a6211&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_b46eb99a6211&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_4ec32941b467)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Hist + MACD + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: -0.21719471758512254\nRoot Mean Squared Error (RMSE) on test data = 2.81502\nestimator: estimator to be cross-validated (current: Pipeline_7a8c1328984c)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_9f2cc3686d53&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_9f2cc3686d53&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_c5d04647b055)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.5825555716073947\nRoot Mean Squared Error (RMSE) on test data = 1.00699\nestimator: estimator to be cross-validated (current: Pipeline_b9061bf53532)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_25b27e7177c1&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_25b27e7177c1&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_ea55b7c76edf)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD + MACD_Hist + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.6651533543787265\nRoot Mean Squared Error (RMSE) on test data = 1.51953\nestimator: estimator to be cross-validated (current: Pipeline_2daa230392a9)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_9ea7261feee6&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_9ea7261feee6&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_7422bec41906)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.5635839918886696\nRoot Mean Squared Error (RMSE) on test data = 2.75411\nestimator: estimator to be cross-validated (current: Pipeline_49667434acf6)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_4c9676e2753d&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_4c9676e2753d&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_0ff432f5b61b)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA_x + EMA_y + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.790991836947174\nRoot Mean Squared Error (RMSE) on test data = 2.0179\nestimator: estimator to be cross-validated (current: Pipeline_badb0d18691b)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_94710cfbd9a2&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_94710cfbd9a2&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_aacdd242f4e2)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD + MACD_Hist + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.8604935355917289\nRoot Mean Squared Error (RMSE) on test data = 4.40985\nestimator: estimator to be cross-validated (current: Pipeline_2a1d0c0a3f69)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_a46bdd8f026b&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_a46bdd8f026b&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_5567c13eb859)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD + MACD_Hist + RSI + SlowD + SlowK + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.625990841710762\nRoot Mean Squared Error (RMSE) on test data = 1.53299\nestimator: estimator to be cross-validated (current: Pipeline_195638bab67d)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_779986ed67ff&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_779986ed67ff&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_3e073345f115)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Hist + MACD + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.4043532032384801\nRoot Mean Squared Error (RMSE) on test data = 3.17542\nestimator: estimator to be cross-validated (current: Pipeline_6fdd2afc1034)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_84b1fbf28d28&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_84b1fbf28d28&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_f49245125b66)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD + MACD_Hist + MACD_Signal + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: 0.3526133722884067\nRoot Mean Squared Error (RMSE) on test data = 1.61553\nestimator: estimator to be cross-validated (current: Pipeline_b0c0c2dd8101)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_211baacba61d&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_211baacba61d&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_250aaedeff08)\nseed: random seed. (default: 7809051150349531440)\nNumber of training records: 1402\nNumber of testing records : 214\nFormula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nr2_score: -0.04517011915054803\nRoot Mean Squared Error (RMSE) on test data = 2.14958\nestimator: estimator to be cross-validated (current: Pipeline_df3e63033087)\nestimatorParamMaps: estimator param maps (current: [{Param(parent=&#39;LinearRegression_1f4464a616b8&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;LinearRegression_1f4464a616b8&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.04}])\nevaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: RegressionEvaluator_540bac171e09)\nseed: random seed. (default: 7809051150349531440)\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["pdata = df_data2.toPandas()\npdata.tail(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n      <th>DailyDate</th>\n      <th>SMA</th>\n      <th>EMA</th>\n      <th>MACD_Signal</th>\n      <th>MACD_Hist</th>\n      <th>MACD</th>\n      <th>RSI</th>\n      <th>SlowK</th>\n      <th>SlowD</th>\n      <th>ADX</th>\n      <th>CCI</th>\n      <th>close_lag7D</th>\n      <th>close_lag14D</th>\n      <th>close_lag28D</th>\n      <th>close_lag50D</th>\n      <th>close_lag200D</th>\n      <th>dateSMA7</th>\n      <th>dateSMA14</th>\n      <th>dateSMA28</th>\n      <th>dateSMA50</th>\n      <th>dateSMA200</th>\n      <th>date_converted</th>\n      <th>DateofMon</th>\n      <th>Month</th>\n      <th>Year</th>\n      <th>WeekSeq</th>\n      <th>SMA50</th>\n      <th>SMA200</th>\n      <th>SMA7</th>\n      <th>SMA14</th>\n      <th>SMA28</th>\n      <th>Delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1612</th>\n      <td>83.05</td>\n      <td>2017-03-31</td>\n      <td>84.5305</td>\n      <td>84.1665</td>\n      <td>-0.2333</td>\n      <td>-0.2192</td>\n      <td>-0.4525</td>\n      <td>41.9830</td>\n      <td>56.4248</td>\n      <td>65.8836</td>\n      <td>18.2914</td>\n      <td>-78.3132</td>\n      <td>82.68</td>\n      <td>84.03</td>\n      <td>85.50</td>\n      <td>75.78</td>\n      <td>75.78</td>\n      <td>83.400000</td>\n      <td>83.650909</td>\n      <td>84.595238</td>\n      <td>84.988333</td>\n      <td>83.052929</td>\n      <td>1.490918e+09</td>\n      <td>31</td>\n      <td>3</td>\n      <td>7.0</td>\n      <td>348</td>\n      <td>83.9632</td>\n      <td>82.67850</td>\n      <td>83.340000</td>\n      <td>84.073571</td>\n      <td>85.160714</td>\n      <td>1.28470</td>\n    </tr>\n    <tr>\n      <th>1613</th>\n      <td>82.95</td>\n      <td>2017-04-03</td>\n      <td>84.3840</td>\n      <td>84.0506</td>\n      <td>-0.2843</td>\n      <td>-0.2040</td>\n      <td>-0.4883</td>\n      <td>41.4489</td>\n      <td>32.7816</td>\n      <td>53.7774</td>\n      <td>18.6798</td>\n      <td>-75.4789</td>\n      <td>82.57</td>\n      <td>84.28</td>\n      <td>85.25</td>\n      <td>76.00</td>\n      <td>76.00</td>\n      <td>83.396667</td>\n      <td>83.381818</td>\n      <td>84.455238</td>\n      <td>85.052571</td>\n      <td>83.069275</td>\n      <td>1.491178e+09</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>348</td>\n      <td>83.9878</td>\n      <td>82.67750</td>\n      <td>83.335714</td>\n      <td>83.898571</td>\n      <td>85.041429</td>\n      <td>1.31030</td>\n    </tr>\n    <tr>\n      <th>1614</th>\n      <td>82.50</td>\n      <td>2017-04-04</td>\n      <td>84.2095</td>\n      <td>83.9029</td>\n      <td>-0.3368</td>\n      <td>-0.2099</td>\n      <td>-0.5467</td>\n      <td>39.0933</td>\n      <td>17.9678</td>\n      <td>35.7247</td>\n      <td>19.2433</td>\n      <td>-87.6173</td>\n      <td>82.48</td>\n      <td>85.92</td>\n      <td>84.96</td>\n      <td>76.47</td>\n      <td>76.47</td>\n      <td>83.220000</td>\n      <td>83.188182</td>\n      <td>84.294286</td>\n      <td>84.981667</td>\n      <td>83.077246</td>\n      <td>1.491264e+09</td>\n      <td>4</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>348</td>\n      <td>84.0068</td>\n      <td>82.67675</td>\n      <td>83.268571</td>\n      <td>83.662857</td>\n      <td>84.881071</td>\n      <td>1.33005</td>\n    </tr>\n    <tr>\n      <th>1615</th>\n      <td>81.17</td>\n      <td>2017-04-05</td>\n      <td>84.0100</td>\n      <td>83.6426</td>\n      <td>-0.4079</td>\n      <td>-0.2845</td>\n      <td>-0.6924</td>\n      <td>33.2197</td>\n      <td>14.9022</td>\n      <td>21.8838</td>\n      <td>20.5496</td>\n      <td>-151.8662</td>\n      <td>83.13</td>\n      <td>85.92</td>\n      <td>84.51</td>\n      <td>77.40</td>\n      <td>77.40</td>\n      <td>82.791667</td>\n      <td>83.002727</td>\n      <td>84.064762</td>\n      <td>84.918889</td>\n      <td>83.074928</td>\n      <td>1.491350e+09</td>\n      <td>5</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>348</td>\n      <td>84.0056</td>\n      <td>82.66795</td>\n      <td>82.927143</td>\n      <td>83.341429</td>\n      <td>84.651071</td>\n      <td>1.33765</td>\n    </tr>\n    <tr>\n      <th>1616</th>\n      <td>81.66</td>\n      <td>2017-04-06</td>\n      <td>83.8275</td>\n      <td>83.4538</td>\n      <td>-0.4782</td>\n      <td>-0.2813</td>\n      <td>-0.7595</td>\n      <td>36.8965</td>\n      <td>23.9270</td>\n      <td>18.9323</td>\n      <td>21.7906</td>\n      <td>-140.4961</td>\n      <td>82.82</td>\n      <td>85.89</td>\n      <td>81.73</td>\n      <td>77.02</td>\n      <td>77.02</td>\n      <td>82.440000</td>\n      <td>82.878182</td>\n      <td>83.898095</td>\n      <td>84.859722</td>\n      <td>83.064748</td>\n      <td>1.491437e+09</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>348</td>\n      <td>83.9982</td>\n      <td>82.66025</td>\n      <td>82.630000</td>\n      <td>83.037857</td>\n      <td>84.452500</td>\n      <td>1.33795</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["formula = \"{} ~ {}\".format(\"close_lag7D\", \" + \".join(columns))\nprint(\"Formula : {}\".format(formula))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Formula : close_lag7D ~ close + SMA + EMA + MACD_Signal + MACD_Hist + MACD + RSI + SlowK + SlowD + ADX + CCI + dateSMA7 + dateSMA14 + dateSMA28 + dateSMA50 + dateSMA200 + date_converted + DateofMon + Month + Year + WeekSeq + SMA50 + SMA200 + SMA7 + SMA14 + SMA28 + Delta\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["#pdata = train_data.toPandas()\n#pdata.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# HERE THE collected data is written to a csv file. \n# This csv file is uploaded to S3\n\npandas_result_summary = result_summary.toPandas()\npandas_result_summary = pandas_result_summary.iloc[2:]\npandas_result_summary.to_csv(\"GBr2results_withfeatures.csv\")\ndbutils.fs.cp('file:/databricks/driver/r2results_withfeatures.csv','dbfs:/mnt/s3datav3/results/r2results_withfeatures.csv')\npandas_result_summary.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1344289081075472&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> pandas_result_summary <span class=\"ansi-blue-fg\">=</span> pandas_result_summary<span class=\"ansi-blue-fg\">.</span>iloc<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> pandas_result_summary<span class=\"ansi-blue-fg\">.</span>to_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;GBr2results_withfeatures.csv&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\"> </span>dbutils<span class=\"ansi-blue-fg\">.</span>fs<span class=\"ansi-blue-fg\">.</span>cp<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;file:/databricks/driver/r2results_withfeatures.csv&#39;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;dbfs:/mnt/s3datav3/results/r2results_withfeatures.csv&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> pandas_result_summary<span class=\"ansi-blue-fg\">.</span>head<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1588439074297-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    312</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    313</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 314</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    315</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    316</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling z:com.databricks.backend.daemon.dbutils.FSUtils.cp.\n: java.io.FileNotFoundException: File file:/databricks/driver/r2results_withfeatures.csv does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$$anonfun$cp$1$$anonfun$apply$3.apply(DBUtilsCore.scala:114)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$$anonfun$cp$1$$anonfun$apply$3.apply(DBUtilsCore.scala:113)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.com$databricks$backend$daemon$dbutils$FSUtils$$withFsSafetyCheck(DBUtilsCore.scala:81)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$$anonfun$cp$1.apply(DBUtilsCore.scala:113)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$$anonfun$cp$1.apply(DBUtilsCore.scala:113)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.com$databricks$backend$daemon$dbutils$FSUtils$$withFsSafetyCheck(DBUtilsCore.scala:81)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.cp(DBUtilsCore.scala:112)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.cp(DBUtilsCore.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["#df_data2.show(10)\ndf_data3 = df_data2['close','DailyDate','close_lag7D']\ndf_data3.show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------------------+-----------+\nclose|          DailyDate|close_lag7D|\n+-----+-------------------+-----------+\n35.18|2010-11-03 00:00:00|      34.83|\n35.95|2010-11-04 00:00:00|      34.51|\n35.14|2010-11-05 00:00:00|      34.01|\n35.09|2010-11-08 00:00:00|      34.01|\n35.24|2010-11-09 00:00:00|      34.42|\n35.11|2010-11-10 00:00:00|      34.76|\n35.21|2010-11-11 00:00:00|      34.89|\n34.83|2010-11-12 00:00:00|      33.98|\n34.51|2010-11-15 00:00:00|      34.31|\n34.01|2010-11-16 00:00:00|      33.68|\n+-----+-------------------+-----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["import matplotlib.pyplot as plt  \nfrom pylab import rcParams\nimport seaborn as sns  \n\npdata = df_data3.toPandas()\nrcParams['figure.figsize'] = 25, 10\nfig = plt.figure()\n\nax1 = sns.lineplot(data=pdata, x=\"DailyDate\", y=\"close\", markers=True, dashes=False,label ='raw close')\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avg7\", markers=True, dashes=False)\nax1 = sns.lineplot(data=pdata, x=\"DailyDate\", y=\"close_lag7D\", markers=True, dashes=False,label ='close_lag7D')\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avg28\", markers=True, dashes=False)\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avgof14D_lag7D\", markers=True, dashes=False,label ='avgof14D_lag7D')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#firstrow = spark.createDataFrame([(stock,format(r2_score),format(rmse),format(r2_score),format(rmse))], r2_columns)\n#result_summary = result_summary.union(firstrow )\n\n\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["train_data.show(5)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#from pyspark.sql.functions import monotonically_increasing_id, lag\n#from pyspark.sql.window import Window\n\n#write_train_data = train_data['DailyDate','close']\n#write_test_data = test_data['DailyDate']\n#write_test_data = test_data.withColumn('id', monotonically_increasing_id())\n#temp = y_true['label']\n\n#write_test_data = write_test_data.withColumn('y_true', temp)\n#write_test_data = write_test_data.withColumn('y_pred', y_pred)\n\n\n"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["import matplotlib.pyplot as plt  \nfrom pylab import rcParams\nimport seaborn as sns  \n\ndata_zoom = write_train_data #df_stg2[(df_stg2['date'] > '2017-01-01' )]\npdata = data_zoom.toPandas()\n\nrcParams['figure.figsize'] = 25, 10\nfig = plt.figure()\n\nax1 = sns.lineplot(data=write_train_data, x=\"DailyDate\", y=\"close\", markers=True, dashes=False,label ='raw open')\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avg7\", markers=True, dashes=False)\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avgof14D_lag0D\", markers=True, dashes=False,label ='avgof14D_lag0D')\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avg28\", markers=True, dashes=False)\n#ax1 = sns.lineplot(data=pdata, x=\"date\", y=\"avgof14D_lag7D\", markers=True, dashes=False,label ='avgof14D_lag7D')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["test_data\ncolumns.remove('DailyDate')"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["print(result_summary)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["bestModel = cvModel.bestModel\nbestModel.stages[-1]._java_obj.parent().getRegParam()\n#bestModel.getParam\n"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["bestModel.save(\"/tmp/rf20200501a\")"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["rfPath = \"/tmp/rf20200501a\"\nsameRFModel = PipelineModel.load(rfPath)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["sameRFModel\npredictions = sameRFModel.transform(test_data)\nevaluator = RegressionEvaluator(labelCol=\"label\",\n                                  predictionCol=\"prediction\",\n                                  metricName=\"rmse\")"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nresult_summary  = pd.DataFrame([])\nfor i in np.arange(0, 4):\n    if i % 2 == 0:\n        result_summary.append(pd.DataFrame({'A': i, 'B': i + 1}, index=[0]), ignore_index=True)\nresult_summary.head()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["print('done')\n#%sh\n#ls\n#%sh\n#ls -lrt"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["cvModel.save('file:/databricks/driver/'+stock+'.csv')"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["dbutils.fs.mkdirs(\"/mnt/\"+MOUNT_NAME +\"/allmodels/\")"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["best_lr = cvModel.bestModel\nbest_lr.save(\"/mnt/\"+MOUNT_NAME +\"/allmodels/testcvmodel/\") "],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["rfPath = \"/mnt/\"+MOUNT_NAME +\"/allmodels/testcvmodel/\"\nsameRFModel = PipelineModel.load(rfPath)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":36}],"metadata":{"name":"SmartFolio_v11_fit_multiplemodels_compare","notebookId":1344289081075457},"nbformat":4,"nbformat_minor":0}
